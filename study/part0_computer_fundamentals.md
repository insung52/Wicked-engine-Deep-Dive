# Part 0: 컴퓨터 기초 (C 아래 레벨)

renderer.cpp를 이해하려면 "코드가 실제로 어떻게 실행되는지"를 알아야 한다.
이 문서는 C/C++ 문법은 알지만 그 아래 레벨은 모르는 사람을 위한 기초 가이드다.

---

## 0.1 메모리 구조 (스택/힙/정적)

### 프로그램이 실행되면 메모리에서 무슨 일이?

프로그램을 실행하면 운영체제가 그 프로그램을 위한 **메모리 공간**을 할당한다.
이 공간은 크게 5개 영역으로 나뉜다:

```
높은 주소 ┌─────────────────┐
         │      Stack      │  ← 지역 변수, 함수 호출 정보
         │        ↓        │
         │                 │
         │        ↑        │
         │      Heap       │  ← 동적 할당 (new, malloc)
         ├─────────────────┤
         │      BSS        │  ← 초기화 안 된 전역/정적 변수 (0으로 초기화)
         ├─────────────────┤
         │      Data       │  ← 초기화된 전역/정적 변수
         ├─────────────────┤
         │      Code       │  ← 실행할 기계어 코드
낮은 주소 └─────────────────┘
```

### 각 영역의 특징

#### 1. Code (Text) 영역
```cpp
int add(int a, int b) {
    return a + b;
}
```
이 함수는 컴파일되면 기계어로 변환되어 Code 영역에 저장된다.
**읽기 전용**이다. 실행 중에 코드가 바뀌면 안 되니까.

#### 2. Data 영역 (전역/정적 변수)
```cpp
int globalCounter = 0;           // Data 영역 (초기화됨)
static int moduleCounter = 0;    // Data 영역 (초기화됨)
int uninitializedGlobal;         // BSS 영역 (0으로 초기화)

void foo() {
    static int callCount = 0;    // Data 영역 - 함수 안이지만 static!
    callCount++;
}
```

**핵심**: 프로그램 시작부터 끝까지 메모리에 존재한다.
- 초기화된 전역/정적 → Data 영역
- 초기화 안 된 전역/정적 → BSS 영역 (자동으로 0)

**BSS (Block Started by Symbol)**:
- 초기화하지 않은 전역/정적 변수가 저장됨
- 프로그램 시작 시 OS가 자동으로 0으로 채움
- 실행 파일에 실제 데이터 없음 (크기 정보만) → 실행 파일 크기 절약

#### 3. Stack 영역 (지역 변수, 함수 호출)
```cpp
void functionA() {
    int localVar = 10;      // Stack에 4바이트 할당
    int array[100];         // Stack에 400바이트 할당
    functionB();            // functionB의 스택 프레임이 위에 쌓임
}   // 함수 끝나면 localVar, array 자동으로 사라짐
```

**스택의 동작 원리**:
```
functionA() 호출 전:
┌─────────────────┐
│    (비어있음)    │
└─────────────────┘

functionA() 진입:
┌─────────────────┐
│ return address  │  ← functionA 끝나면 어디로 돌아갈지
│ localVar = 10   │
│ array[100]      │
└─────────────────┘

functionA()에서 functionB() 호출:
┌─────────────────┐
│ return address  │  ← functionB 끝나면 어디로?
│ functionB 지역들│
├─────────────────┤
│ return address  │
│ localVar = 10   │
│ array[100]      │
└─────────────────┘

functionB() 끝:
┌─────────────────┐
│ return address  │
│ localVar = 10   │
│ array[100]      │
└─────────────────┘
```

**스택의 특징**:
- 매우 빠름 (포인터 하나만 이동)
- 크기 제한 있음 (보통 1~8MB)
- 자동 정리 (함수 끝나면 알아서 해제)

**스택 오버플로우**:
```cpp
void recursive() {
    int bigArray[10000];  // 매 호출마다 40KB
    recursive();          // 무한 재귀 → 스택 터짐
}
```

#### 4. Heap 영역 (동적 할당)
```cpp
void example() {
    // Stack: 포인터 변수 ptr (8바이트, 64bit 시스템)
    // Heap: 실제 데이터 400바이트
    int* ptr = new int[100];

    // ... 사용 ...

    delete[] ptr;  // 직접 해제해야 함!
}
```

**Heap의 특징**:
- RAM 크기랑 상관없이 주소를 잡을 수 있다
    - 실제 사용시에 ram 할당됨
    - ram 공간 부족시 Swap(OS가 안 쓰는 페이지를 디스크로 밀어내 공간 확보)
- 느림 (빈 공간 찾아야 함)
- 직접 관리 필요 (memory leak 주의)

### 실제 예시: 어디에 할당될까?

```cpp
int global = 1;                    // Data

class Renderer {
    static int instanceCount;      // Data (static 멤버)
    int width;                     // 이건 객체가 어디 있냐에 따라 다름

    void render() {
        int frameCount = 0;        // Stack

        float* buffer = new float[1920*1080*4];  // Heap

        // buffer 포인터 자체는 Stack (8바이트)
        // buffer가 가리키는 데이터는 Heap (약 31MB)

        delete[] buffer;
    }
};

int main() {
    Renderer r1;                   // Stack에 Renderer 객체
    Renderer* r2 = new Renderer;   // Heap에 Renderer 객체

    delete r2;
}
```

### 왜 이게 그래픽스에서 중요한가?

```cpp
// 나쁜 예: 매 프레임 Heap 할당
void render() {
    std::vector<Vertex> vertices;  // 매번 new/delete 발생
    // ...
}

// 좋은 예: 미리 할당해두고 재사용
class Renderer {
    std::vector<Vertex> vertices;  // 멤버로 유지

    void render() {
        vertices.clear();  // 메모리는 유지, 내용만 비움
        // ...
    }
};
```

그래픽스는 **초당 60번** 이상 같은 작업을 반복한다.
매번 메모리 할당/해제하면 성능이 박살난다.

---

## 0.2 CPU 명령어가 실행되는 과정

### C 코드 → 실행까지

```cpp
int result = a + b;
```

이 한 줄이 실행되려면:

```
1. 소스 코드 (.cpp)
        ↓ [컴파일러]
2. 어셈블리어
        ↓ [어셈블러]
3. 기계어/오브젝트 파일 (.obj)
        ↓ [링커]
4. 실행 파일 (.exe)
        ↓ [로더]
5. 메모리에 적재
        ↓ [CPU]
6. 실행!
```

### 어셈블리어란?

기계어(0101...)를 사람이 읽을 수 있게 1:1 대응시킨 것.

```cpp
int add(int a, int b) {
    return a + b;
}
```

컴파일하면 (x64 기준):
```asm
add:
    mov     eax, ecx      ; a를 eax 레지스터로
    add     eax, edx      ; eax = eax + b
    ret                   ; eax에 있는 값이 리턴값
```

### CPU의 구조 (매우 단순화)

```
┌────────────────────────────────────────┐
│                  CPU                    │
│  ┌──────────┐    ┌──────────────────┐  │
│  │ 레지스터  │    │   ALU (연산장치)  │  │
│  │ eax, ebx │───→│  덧셈, 뺄셈, ...  │  │
│  │ ecx, edx │    └──────────────────┘  │
│  │ ...      │                          │
│  └──────────┘    ┌──────────────────┐  │
│        ↑         │  Control Unit    │  │
│        │         │  (명령어 해석)    │  │
│        │         └──────────────────┘  │
└────────│───────────────────────────────┘
         │
         ↓
    ┌─────────┐
    │ 메모리   │
    │ (RAM)   │
    └─────────┘
```

**레지스터**: CPU 내부의 초고속 저장소. 아주 작음 (x64: 16개의 64비트 레지스터)

### 명령어 실행 사이클

CPU는 이걸 무한 반복한다:

```
1. Fetch (인출)    : 메모리에서 다음 명령어를 가져옴
2. Decode (해석)   : 무슨 명령인지 해석
3. Execute (실행)  : 실제로 연산 수행
4. Write-back     : 결과를 레지스터/메모리에 저장
```

예시:
```asm
mov eax, [address]   ; 메모리에서 값을 eax로
add eax, 5           ; eax에 5를 더함
mov [address], eax   ; 결과를 메모리에 저장
```

### 파이프라이닝

CPU는 한 번에 하나씩 안 하고, 여러 명령을 동시에 처리한다:

```
시간 →
명령1: [Fetch][Decode][Execute][Write]
명령2:       [Fetch][Decode][Execute][Write]
명령3:              [Fetch][Decode][Execute][Write]
```

이래서 CPU가 빠른 거다.

### 왜 이게 그래픽스에서 중요한가?

**분기(if문)는 파이프라인을 망친다**:
```cpp
// 나쁜 예: 분기 예측 실패 시 파이프라인 비워야 함
for (int i = 0; i < 1000000; i++) {
    // if (i < 1000)   이런 건 예측 100%에 가깝다
    if (random_condition()) {  // 예측 불가
        doA();
    } else {
        doB();
    }
}

// 좋은 예: 분기 없이 처리
for (int i = 0; i < 1000000; i++) {
    result = condition * valueA + (!condition) * valueB;
}
```

GPU 셰이더에서 이게 더 심각해진다. 나중에 다룸. (예측기 거의 없음)

---

## 0.3 캐시 메모리와 메모리 계층

### 메모리 속도의 현실

```
레지스터    : 1 사이클 (0.3ns)
L1 캐시     : ~4 사이클 (1ns)
L2 캐시     : ~12 사이클 (3ns)
L3 캐시     : ~40 사이클 (12ns)
RAM         : ~200 사이클 (60ns)
SSD         : ~100,000 사이클 (30μs)
HDD         : ~10,000,000 사이클 (3ms)
```

**CPU는 RAM보다 200배 빠르다.**
매번 RAM에서 데이터 가져오면 CPU가 놀고 있어야 한다.

### 캐시란?

자주 쓰는 데이터를 CPU 가까이에 복사해두는 것.

```
┌───────────────────────────────────────────┐
│                   CPU                      │
│   ┌─────────┐                             │
│   │ 레지스터 │                             │
│   └────┬────┘                             │
│        │                                  │
│   ┌────┴────┐  32KB, 가장 빠름            │
│   │ L1 캐시  │  (코어마다 별도)            │
│   └────┬────┘                             │
│        │                                  │
│   ┌────┴────┐  256KB                      │
│   │ L2 캐시  │  (코어마다 별도)            │
│   └────┬────┘                             │
│        │                                  │
│   ┌────┴────┐  8~32MB                     │
│   │ L3 캐시  │  (모든 코어 공유)           │
│   └────┬────┘                             │
└────────│──────────────────────────────────┘
         │
    ┌────┴────┐  8~64GB
    │   RAM   │
    └─────────┘
```

### 캐시 히트 vs 캐시 미스

```cpp
int array[1000000];

// 캐시 히트: 연속 접근
for (int i = 0; i < 1000000; i++) {
    sum += array[i];  // 빠름!
}

// 캐시 미스: 랜덤 접근
for (int i = 0; i < 1000000; i++) {
    sum += array[random_index()];  // 느림!
}
```

**캐시 라인**: CPU는 데이터를 1바이트씩 안 가져오고, **64바이트** 단위로 가져온다.

```cpp
struct Bad {
    int id;           // 4 bytes
    char padding[60]; // 60 bytes - 캐시 라인 낭비
    int value;        // 4 bytes - 다음 캐시 라인
};

struct Good {
    int id;           // 4 bytes
    int value;        // 4 bytes - 같은 캐시 라인!
};

Bad badArray[1000];   // 순회하면 캐시 미스 많음
Good goodArray[1000]; // 순회하면 캐시 히트 많음
```

### Data-Oriented Design (DOD)

전통적 OOP:
```cpp
struct Particle {
    Vector3 position;
    Vector3 velocity;
    float lifetime;
    Color color;
    bool active;
    // ... 기타 등등
};

std::vector<Particle> particles;

// 위치만 업데이트하는데 전체 구조체를 캐시에 로드
for (auto& p : particles) {    //auto& : 참조, auto : 복사본
    p.position += p.velocity * dt;
}
```

DOD 스타일:
```cpp
struct ParticleSystem {
    std::vector<Vector3> positions;   // 위치만 모아둠
    std::vector<Vector3> velocities;  // 속도만 모아둠
    std::vector<float> lifetimes;
    // ...
};

// 필요한 데이터만 캐시에 로드
for (int i = 0; i < count; i++) {
    positions[i] += velocities[i] * dt;
}
```

**그래픽스 엔진들이 ECS(Entity Component System)를 쓰는 이유가 이거다.**

---

## 0.4 CPU vs GPU 아키텍처 차이

### CPU: 적은 코어, 복잡한 작업

```
CPU (예: Intel i7)
┌─────────────────────────────────────────┐
│  ┌─────────────────┐  ┌─────────────────┐│
│  │     Core 0      │  │     Core 1      ││
│  │  ┌───────────┐  │  │  ┌───────────┐  ││
│  │  │ 복잡한     │  │  │  │ 복잡한     │  ││
│  │  │ 제어로직   │  │  │  │ 제어로직   │  ││
│  │  │ 분기예측   │  │  │  │ 분기예측   │  ││
│  │  │ 큰 캐시    │  │  │  │ 큰 캐시    │  ││
│  │  └───────────┘  │  │  └───────────┘  ││
│  └─────────────────┘  └─────────────────┘│
│                                          │
│  ┌─────────────────┐  ┌─────────────────┐│
│  │     Core 2      │  │     Core 3      ││
│  │      ...        │  │      ...        ││
│  └─────────────────┘  └─────────────────┘│
└─────────────────────────────────────────┘
```

**특징**:
- 코어 수: 4~16개
- 각 코어가 독립적으로 다른 작업 가능
- 복잡한 분기, 재귀 잘 처리
- 순차적 작업에 최적화

### GPU: 엄청 많은 코어, 단순한 작업

```
GPU (예: RTX 3080)
┌───────────────────────────────────────────────────┐
│ SM 0          SM 1          SM 2         ...      │
│ ┌───────────┐ ┌───────────┐ ┌───────────┐         │
│ │■■■■■■■■■■ │ │■■■■■■■■■■ │ │■■■■■■■■■■ │         │
│ │■■■■■■■■■■ │ │■■■■■■■■■■ │ │■■■■■■■■■■ │         │
│ │■■■■■■■■■■ │ │■■■■■■■■■■ │ │■■■■■■■■■■ │         │
│ │■■■■■■■■■■ │ │■■■■■■■■■■ │ │■■■■■■■■■■ │  x 68   │
│ └───────────┘ └───────────┘ └───────────┘   SMs   │
│    128개         128개         128개               │
│    CUDA코어     CUDA코어      CUDA코어              │
│                                                   │
│          총 8704개 CUDA 코어!                      │
└───────────────────────────────────────────────────┘
```

**특징**:
- 코어 수: 수천 개
- 모든 코어가 **같은 명령**을 실행 (SIMD)
- 분기 처리 매우 느림
- 병렬 작업에 최적화

### SIMD (Single Instruction, Multiple Data)

CPU 방식:
```cpp
// 4개의 덧셈을 순차적으로
for (int i = 0; i < 4; i++) {
    c[i] = a[i] + b[i];
}
```

GPU 방식:
```cpp
// 4개의 덧셈을 동시에!
// 코어0: c[0] = a[0] + b[0]
// 코어1: c[1] = a[1] + b[1]
// 코어2: c[2] = a[2] + b[2]
// 코어3: c[3] = a[3] + b[3]
```

### GPU에서 분기가 느린 이유

```cpp
// 셰이더 코드
if (pixelBrightness > 0.5) {
    doExpensiveOperation();
} else {
    doSimpleOperation();
}
```

GPU에서 일어나는 일:
```
32개 픽셀이 한 그룹(Warp/Wavefront)으로 실행된다고 가정

픽셀 0~15: brightness > 0.5 (true)
픽셀 16~31: brightness <= 0.5 (false)

실제 실행:
1. 모든 32개가 doExpensiveOperation 실행
   - 단, 픽셀 16~31은 결과를 버림 (마스킹)
2. 모든 32개가 doSimpleOperation 실행
   - 단, 픽셀 0~15는 결과를 버림 (마스킹)

→ 두 경로를 모두 실행해야 함! (성능 반토막)
```

이걸 **Warp Divergence** 또는 **Thread Divergence**라고 부른다.

### 비유로 이해하기

**CPU = 박사 4명**
- 각자 다른 복잡한 연구 가능
- "만약 A면 B하고, 아니면 C해" → 잘 처리

**GPU = 초등학생 8000명**
- 단순한 계산은 엄청 빠름
- 모두에게 "3+5 계산해!" → 순식간에 끝
- "각자 다른 문제 풀어" → 혼란
- "조건에 따라 다르게 해" → 절반은 기다려야 함

### 그래픽스에서의 적용

화면에 1920x1080 = 2,073,600 픽셀이 있다.
각 픽셀에 대해 색상 계산해야 한다.

CPU: 4개 코어로 200만 번 계산 → 느림
GPU: 8000개 코어로 동시에 계산 → 빠름

이래서 그래픽스는 GPU를 쓴다.

---

## 0.5 PCIe와 CPU-GPU 통신

### 시스템 구조

```
┌─────────────┐              ┌─────────────┐
│     CPU     │              │     GPU     │
│             │              │             │
│  ┌───────┐  │              │  ┌───────┐  │
│  │ L3캐시│  │              │  │ VRAM  │  │
│  └───┬───┘  │              │  │ 8~24GB│  │
│      │      │              │  └───┬───┘  │
└──────│──────┘              └──────│──────┘
       │                            │
    ┌──┴──┐                     ┌───┴──┐
    │ RAM │                     │ GPU  │
    │     │                     │메모리│
    └──┬──┘                     └───┬──┘
       │         PCIe 버스          │
       └────────────────────────────┘
             (16GB/s ~ 64GB/s)
```

### PCIe란?

**P**eripheral **C**omponent **I**nterconnect **e**xpress

CPU와 GPU(또는 다른 장치)를 연결하는 고속 버스.

```
PCIe 3.0 x16: ~16 GB/s
PCIe 4.0 x16: ~32 GB/s
PCIe 5.0 x16: ~64 GB/s

비교:
- RAM 대역폭: ~50 GB/s
- GPU VRAM 대역폭: ~900 GB/s (RTX 3080)
```

**핵심**: GPU 내부는 엄청 빠르지만, CPU↔GPU 통신은 상대적으로 느리다.

### CPU에서 GPU로 데이터 보내기

```cpp
// 1. CPU에서 데이터 준비 (RAM에 있음)
std::vector<Vertex> vertices = loadModel();

// 2. GPU로 복사 (PCIe 통해서)
ID3D12Resource* vertexBuffer;
// ... GPU 버퍼 생성 ...
void* mappedData = deviceBuffer.map();  // GPU 버퍼를 CPU 주소 공간에 매핑
memcpy(mappedData, vertices.data(), size);  // CPU 에서 mappedData 로 복사

// 3. GPU에서 사용
// 이제 vertexBuffer는 VRAM에 있음

deviceBuffer.unmap();
```

### 동기화 문제

```cpp
// 프레임 1
uploadDataToGPU(data1);    // CPU가 GPU에 데이터 전송
renderFrame();              // GPU가 렌더링 시작
// GPU가 아직 렌더링 중인데...

// 프레임 2
uploadDataToGPU(data2);    // CPU가 같은 버퍼에 새 데이터 쓰면?
// GPU: "어? 데이터가 바뀌었네?" → 그래픽 깨짐!
```

그래서 **동기화**가 필요하다:
```cpp
// 방법 1: 기다리기 (느림)
uploadDataToGPU(data1);
waitForGPU();              // GPU 끝날 때까지 CPU가 대기
uploadDataToGPU(data2);

// 방법 2: 더블/트리플 버퍼링 (빠름)
// 버퍼를 여러 개 만들어서 번갈아 사용
uploadDataToGPU(buffer[0], data1);  // GPU가 buffer[1] 사용 중
// 다음 프레임
uploadDataToGPU(buffer[1], data2);  // GPU가 buffer[0] 사용 중
```

### 데이터 전송 최소화가 중요한 이유

```cpp
// 나쁜 예: 매 프레임 전체 메시 업로드
void render() {
    uploadAllMeshes();  // 수백 MB를 매 프레임 전송?!
    drawScene();
}

// 좋은 예: 한 번 업로드하고 재사용
void init() {
    uploadAllMeshes();  // 초기화 때 한 번만
}

void render() {
    // 이미 GPU에 있는 데이터 사용
    drawScene();
}
```

**원칙**: GPU에 데이터를 보내는 건 비싸다. 최소화하라.

---

## 0.6 드라이버란 무엇인가

### 드라이버의 역할

```
┌─────────────────────────────────────────────────┐
│                  너의 게임                       │
├─────────────────────────────────────────────────┤
│            그래픽스 API (DX12, Vulkan)          │
├─────────────────────────────────────────────────┤
│                  GPU 드라이버                   │  ← 여기!
├─────────────────────────────────────────────────┤
│                  운영체제 (커널)                 │
├─────────────────────────────────────────────────┤
│                  하드웨어 (GPU)                  │
└─────────────────────────────────────────────────┘
```

드라이버는 **번역가**다.
- 위: "이 삼각형 그려줘" (API 호출)
- 드라이버: 이걸 특정 GPU가 이해하는 명령으로 변환
- 아래: GPU가 실제로 실행

### 왜 드라이버가 필요한가?

GPU 제조사마다 하드웨어가 다르다:
```
NVIDIA RTX 3080:
- CUDA 코어 사용
- 특정 명령어 세트
- 특정 메모리 구조

AMD RX 6800:
- Compute Unit 사용
- 다른 명령어 세트
- 다른 메모리 구조
```

같은 코드가 두 GPU에서 돌아가려면?
→ 드라이버가 각 GPU에 맞게 변환

### API 호출이 GPU 명령이 되기까지

```cpp
// 너의 코드 (DX12)
commandList->DrawInstanced(36, 1, 0, 0);
```

내부에서 일어나는 일:
```
1. [API 레이어]
   DrawInstanced 호출 검증

2. [드라이버 - 유저모드]
   DX12 호출을 드라이버 내부 명령으로 변환
   최적화 (비슷한 호출 묶기 등)

3. [드라이버 - 커널모드]
   GPU 하드웨어 명령으로 변환
   명령을 GPU 큐에 제출

4. [GPU]
   실제로 삼각형 그림
```

### OpenGL vs DX12/Vulkan의 드라이버 차이

**OpenGL (구형 API)**:
```
┌─────────────┐
│  너의 코드   │
├─────────────┤
│   OpenGL    │
├─────────────┤
│             │
│   두꺼운    │  ← 드라이버가 많은 일을 함
│   드라이버   │     - 상태 관리
│             │     - 메모리 관리
│             │     - 동기화
├─────────────┤
│    GPU      │
└─────────────┘
```

**DX12/Vulkan (현대 API)**:
```
┌─────────────┐
│  너의 코드   │  ← 네가 직접 해야 할 일이 많음
│  - 상태관리 │     - 메모리 관리
│  - 동기화   │     - 동기화
├─────────────┤
│ DX12/Vulkan │
├─────────────┤
│   얇은      │  ← 드라이버는 거의 전달만
│  드라이버   │
├─────────────┤
│    GPU      │
└─────────────┘
```

**왜 이렇게 바뀌었나?**
- 두꺼운 드라이버: 쓰기 쉬움, but 오버헤드 큼
- 얇은 드라이버: 어려움, but 성능 최적화 가능

Wicked Engine이 DX12를 쓰는 이유도 이거다.
드라이버 오버헤드를 줄이고 직접 제어하려고.

### 드라이버 버그

드라이버도 소프트웨어라 버그가 있다:
```cpp
// "이 코드는 NVIDIA에서 되는데 AMD에서 안 돼요"
// → 십중팔구 드라이버 차이 또는 버그

// 흔한 패턴
#ifdef NVIDIA_WORKAROUND
    // NVIDIA 드라이버 버그 우회 코드
#endif
```

그래서 게임/엔진 개발자들이 항상 **최신 드라이버**를 권장하는 거다.

---

## 요약

| 개념 | 핵심 |
|------|------|
| 메모리 구조 | Stack(자동, 빠름, 작음) vs Heap(수동, 느림, 큼) |
| CPU 실행 | Fetch→Decode→Execute, 파이프라인, 분기 비용 |
| 캐시 | 연속 접근이 빠름, 캐시 라인 64바이트 |
| CPU vs GPU | CPU=복잡한 작업 소수, GPU=단순한 작업 다수 |
| PCIe | CPU↔GPU 통신은 느림, 데이터 전송 최소화 |
| 드라이버 | API→GPU 명령 변환, DX12는 얇은 드라이버 |

---

## 다음 단계

Part 0을 이해했다면 Part 1(그래픽스 기초 개념)으로 넘어가자.
질문 있으면 언제든 물어봐.
